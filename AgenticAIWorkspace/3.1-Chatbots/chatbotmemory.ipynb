{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "206ba9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03421abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY')\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ['LANGCHAIN_PROJECT'] = os.getenv('LANGCHAIN_PROJECT')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53e1e9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001FFB40AD9D0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001FFB40AD580>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model='llama-3.1-8b-instant')\n",
    "model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93c414e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello. How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 36, 'total_tokens': 46, 'completion_time': 0.010616461, 'prompt_time': 0.001553288, 'queue_time': 0.044379752, 'total_time': 0.012169749}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ab04adca7d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--29e1c452-82b9-4766-ba1e-3910d9029321-0', usage_metadata={'input_tokens': 36, 'output_tokens': 10, 'total_tokens': 46})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Hello\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f56ef347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Namaske Suchitra, it's great to meet you. As a Data Scientist, you must be working with various data sets, developing and implementing machine learning models, and communicating insights to stakeholders. \\n\\nWhat areas of data science are you particularly interested in or specialize in, Suchitra?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 46, 'total_tokens': 105, 'completion_time': 0.091631898, 'prompt_time': 0.002085741, 'queue_time': 0.044291209, 'total_time': 0.093717639}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ab04adca7d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--87c23c03-5b10-450f-8277-997f6286ce75-0', usage_metadata={'input_tokens': 46, 'output_tokens': 59, 'total_tokens': 105})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"My name is Suchitra and I am a Data Scientist\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7626003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Suchitra, and you are a Data Scientist.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 78, 'total_tokens': 92, 'completion_time': 0.019354669, 'prompt_time': 0.00415857, 'queue_time': 0.0452244, 'total_time': 0.023513239}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_e32974efee', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--2f88a5d5-4b4a-4d05-84c7-6f10b97aa06a-0', usage_metadata={'input_tokens': 78, 'output_tokens': 14, 'total_tokens': 92})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke([HumanMessage(content=\"My name is Suchitra and I am a Data Scientist\"),\n",
    "               AIMessage(content=\"Hello Suchitra! How can I assist you today?\"),\n",
    "               HumanMessage(content=\"Hey What is my name and what do i do?\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc893d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id:str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df5b5154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableWithMessageHistory(bound=RunnableBinding(bound=RunnableBinding(bound=RunnableLambda(_enter_history), kwargs={}, config={'run_name': 'load_history'}, config_factories=[])\n",
       "| RunnableBinding(bound=RunnableLambda(_call_runnable_sync), kwargs={}, config={'run_name': 'check_sync_or_async'}, config_factories=[]), kwargs={}, config={'run_name': 'RunnableWithMessageHistory'}, config_factories=[]), kwargs={}, config={}, config_factories=[], get_session_history=<function get_session_history at 0x000001FFB5F085E0>, history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history = RunnableWithMessageHistory(model,get_session_history)\n",
    "with_message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c48c2f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"It's nice to meet you, Suchitra. As a Data Scientist, you have a unique opportunity to work with data to drive business decisions, solve complex problems, and uncover hidden patterns. \\n\\nWhat kind of projects or industries have you worked in or are interested in? Have you worked with any interesting datasets or applied any innovative techniques in your work as a Data Scientist?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 75, 'prompt_tokens': 140, 'total_tokens': 215, 'completion_time': 0.119685578, 'prompt_time': 0.008716849, 'queue_time': 0.04805183, 'total_time': 0.128402427}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ab04adca7d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--1e193690-db42-4967-bc5d-dfec2c9d5d71-0', usage_metadata={'input_tokens': 140, 'output_tokens': 75, 'total_tokens': 215})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {'configurable':{'session_id':\"Suchitra\"}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"My name is Suchitra and I am a Data Scientist\")],\n",
    "    config=config\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ca23423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Suchitra, and you work as a Data Scientist.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 298, 'total_tokens': 313, 'completion_time': 0.013818371, 'prompt_time': 0.016319512, 'queue_time': 0.045051068, 'total_time': 0.030137883}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_e32974efee', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--4cc806da-707b-451e-b6bf-81b6268a5859-0', usage_metadata={'input_tokens': 298, 'output_tokens': 15, 'total_tokens': 313})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {'configurable':{'session_id':\"Suchitra\"}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name and what do I do\")],\n",
    "    config=config\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6967e660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I don't have any information about you. I'm a large language model, I don't have personal knowledge or direct access to information about specific individuals. Our conversation just started, and I don't have any identification of you. If you'd like to share your name and what you do, I'd be happy to chat with you!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 44, 'total_tokens': 113, 'completion_time': 0.094855992, 'prompt_time': 0.001982725, 'queue_time': 0.044930784, 'total_time': 0.096838717}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--49e7f455-531c-4e1e-b946-2a2cca1f3eb0-0', usage_metadata={'input_tokens': 44, 'output_tokens': 69, 'total_tokens': 113})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config1 = {'configurable':{'session_id':\"Krish\"}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name and what do I do\")],\n",
    "    config=config\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4ad1fba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"JOhnC, it's nice to chat with you about your love for vanilla ice cream. What is it about vanilla ice cream that you enjoy the most? Is it the classic flavor, the texture, or something else?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 123, 'total_tokens': 169, 'completion_time': 0.056604141, 'prompt_time': 0.006812587, 'queue_time': 0.044422753, 'total_time': 0.063416728}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_33e8adf159', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--08013eae-7423-44f9-8830-2d986d31ecef-0', usage_metadata={'input_tokens': 123, 'output_tokens': 46, 'total_tokens': 169})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config2 = {'configurable':{'session_id':\"JohnC\"}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"My name is JOhnC and I like Vanilla icecream\")],\n",
    "    config=config2\n",
    "\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0522f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is JOhnC.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 220, 'total_tokens': 228, 'completion_time': 0.003751856, 'prompt_time': 0.012132392, 'queue_time': 0.044317878, 'total_time': 0.015884248}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_33e8adf159', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--5844da64-58e8-482f-9572-60e70788d54f-0', usage_metadata={'input_tokens': 220, 'output_tokens': 8, 'total_tokens': 228})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey what is my name?\")],\n",
    "    config=config2\n",
    "\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b33f7025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Suchitra.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 328, 'total_tokens': 335, 'completion_time': 0.003635098, 'prompt_time': 0.018071805, 'queue_time': 0.044890895, 'total_time': 0.021706903}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--a0f50258-4892-43ab-8f9d-66cfa6491ab6-0', usage_metadata={'input_tokens': 328, 'output_tokens': 7, 'total_tokens': 335})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey what is my name?\")],\n",
    "    config=config\n",
    "\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b619e2",
   "metadata": {},
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47bd204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['language', 'messages'], input_types={'messages': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001FF8BE4B7E0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='You are a helpful Assistant. answer all the question to the best of your ability in {language} language'), additional_kwargs={}), MessagesPlaceholder(variable_name='messages')])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful Assistant. answer all the question to the best of your ability\"),\n",
    "        MessagesPlaceholder(variable_name='messages')\n",
    "    ]\n",
    ")\n",
    "prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "94059fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Nice to meet you, Suchitra. How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 58, 'total_tokens': 74, 'completion_time': 0.0174701, 'prompt_time': 0.002955782, 'queue_time': 0.044523884, 'total_time': 0.020425882}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_33e8adf159', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--f7127eb3-036e-4cf5-84bc-36bb7f70138a-0', usage_metadata={'input_tokens': 58, 'output_tokens': 16, 'total_tokens': 74})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt|model\n",
    "chain.invoke(\n",
    "    {\"messages\": [HumanMessage(content='Hi, My name is Suchitra')]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27237e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Suchitra.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 153, 'total_tokens': 160, 'completion_time': 0.004016621, 'prompt_time': 0.008517746, 'queue_time': 0.0449793, 'total_time': 0.012534367}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ab04adca7d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--897bbf1c-ba96-48ab-9897-2b94c477bae6-0', usage_metadata={'input_tokens': 153, 'output_tokens': 7, 'total_tokens': 160})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history = RunnableWithMessageHistory(chain,get_session_history)\n",
    "config = {\"configurable\":{'session_id':'chat4'}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name\")],\n",
    "    config=config       \n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9bede812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['language', 'messages'], input_types={'messages': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001FF8BE4B7E0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='You are a helpful Assistant. answer all the question to the best of your ability in {language} language'), additional_kwargs={}), MessagesPlaceholder(variable_name='messages')])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001FFB40AD9D0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001FFB40AD580>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful Assistant. answer all the question to the best of your ability in {language} language\"),\n",
    "        MessagesPlaceholder(variable_name='messages')\n",
    "    ]\n",
    ")\n",
    "prompt\n",
    "chain = prompt|model\n",
    "chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "41445b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='नमस्ते Suchitra जी! मैं आपकी सहायता करने के लिए यहाँ हूँ। मैं आपके प्रश्नों का उत्तर देने के लिए तैयार हूँ। कृपया अपना प्रश्न पूछें!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 61, 'total_tokens': 129, 'completion_time': 0.088000643, 'prompt_time': 0.003398058, 'queue_time': 0.045206452, 'total_time': 0.091398701}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_7b3cfae3af', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--c22617c3-2af1-42f6-b872-4f57058c23d2-0', usage_metadata={'input_tokens': 61, 'output_tokens': 68, 'total_tokens': 129})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {'messages':[HumanMessage(content=\"Hi, My name is Suchitra\")],\n",
    "     'language':'Hindi'}\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cabde5c",
   "metadata": {},
   "source": [
    "## Trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "305e1f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"hi! I'm bob\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='hi!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "\n",
    "\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=60,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "trimmer.invoke(messages)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "81f2e8aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  messages: RunnableLambda(itemgetter('messages'))\n",
       "            | RunnableLambda(...)\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['language', 'messages'], input_types={'messages': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x000001FF8BE4B7E0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language'], input_types={}, partial_variables={}, template='You are a helpful Assistant. answer all the question to the best of your ability in {language} language'), additional_kwargs={}), MessagesPlaceholder(variable_name='messages')])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001FFB40AD9D0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001FFB40AD580>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "chain = (RunnablePassthrough.assign(messages=itemgetter('messages')|trimmer)|prompt|model)\n",
    "chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1db6c905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You mentioned earlier that you like vanilla ice cream!'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        'messages': messages + [HumanMessage(content=\"what icecream do i like?\")],\n",
    "        'language':'English'\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb6e8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import ArxivQueryRun,WikipediaQueryRun\n",
    "from langchain_community.utilities import ArxivAPIWrapper,WikipediaAPIWrapper\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
